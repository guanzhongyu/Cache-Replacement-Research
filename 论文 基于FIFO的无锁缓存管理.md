## 高并发场景下元数据缓存的吞吐率问题分析

缓存性能挑战的三项重要指标：


$$
\text{缓存命中率} = \frac{\text{缓存命中次数}}{\text{总请求次数}} \times 100\%
$$

1. 缓存命中率：缓存命中率高说明有效减少了对后端存储的访问，提高命中率的关键在于使用先进的缓存淘汰策略。
2. 并发吞吐率：缓存每秒能够处理的请求数量
3. 缓存延迟：缓存系统处理每个请求所需要的时间缓存延迟指标，尤其是尾延迟成为衡量缓存系统性能的重要因素。

### 客户端元数据缓存的吞吐问题

> 元数据不包含实际内容，而是描述和组织数据的信息。

**元数据缓存如何工作？** 
>1. **首次请求**：当系统第一次需要某个文件的元数据时，它会从慢速的存储设备（如硬盘）中读取，并把这份元数据**同时复制一份到高速缓存**（如内存）中。
>2. **后续请求**：下次再有程序需要这个文件的元数据时，系统会**首先检查缓存**。
>	1. 如果缓存中有，系统会直接从缓存中读取，这个过程非常快。
>	2. 如果缓存中没有，系统才会再次从慢速存储设备中读取，并更新缓存。


根据所在位置，元数据缓存可以分为**客户端缓存、分布式缓存中间层、元数据服务器缓存**三类。
1. 客户端缓存 (Client-Side Cache)
客户端缓存是*离用户最近的一种缓存*，它将数据直接存储在*用户使用的设备上*（如浏览器、移动应用、桌面程序）。这种缓存的目的是为了减少网络请求，让用户再次访问相同内容时能够更快地加载。
2. 分布式缓存中间层 (Distributed Cache Middleware)
分布式缓存中间层是一种*独立的、位于应用和数据库之间的高速缓存系统*。它通常由多台服务器组成，共同存储数据，并为多个应用实例提供服务。它的核心目的是缓解数据库压力，提升应用响应速度。
3. 元数据服务器缓存 (Metadata Server Cache)
元数据服务器缓存，顾名思义，是专门用于缓存**元数据**的。元数据是描述数据的数据，例如文件的大小、创建时间、权限，以及它在存储系统中的物理位置等。这种缓存通常用于大规模的分布式文件系统。
- **工作原理**：在一个大型的分布式存储系统中（如Hadoop HDFS），元数据和实际数据是分开存放的。元数据服务器专门负责管理文件的元数据。当客户端需要访问一个文件时，它首先向元数据服务器请求文件的元数据。元数据服务器会将其经常访问的元数据信息缓存在内存中，这样客户端就能快速获取文件所在的数据节点地址，然后直接与数据节点通信。

客户端缓存通常保存上层目录的相关元数据。一旦用户命中客户端缓存，可以避免冗长的路径解析开销和权限检测开销，提升了元数据性能。也避免了对上层目录所在MDS的频繁访问，减少访问热点，提高了系统的并发能力。
经过分析，**粗粒度锁**的使用是制约元数据缓存的并发能力的罪魁祸首。LRU使用粗粒度锁机制保证线程安全。而元数据尺寸小，访问频繁，*元数据获取开销远小于锁开销*。以上两者共同作用下，锁机制成为元数据缓存的并发瓶颈，恶化了元数据缓存的访问延迟。

### 缓存淘汰策略的分析和对比

![](photo/四种缓存替换策略.png)

1. FIFO：缓存项按照插入的顺序被逐出
2. LRU：缓存项正常插入逐出，被访问时调整位置，移至队列左侧
3. CLOCK：基于FIFO算法改进，每个缓存项关联一个访问标记，当缓存项命中时访问标记置1，从队列右侧选择最旧的缓存项进行处理。若访问标记为1，给予第二次机会，即访问标记被清除，并将该缓存项重新插入到队列左侧，视为新项。CLOCK算法会继续搜索，直到找到一个访问标记为0的旧缓存项淘汰。
4. SIEVE：基于CLOCK算法。SIEVE在缓存项被访问后不会将其重新插入队列，而是将其保留在原位置。SIEVE在淘汰过程中使用一个扫描指针以识别待淘汰的候选项。如果扫描到的缓存项的访问标记为1，表示该项曾被访问过，SIEVE会清除其访问标记并保留该项，同时将扫描指针从右向左移动到队列中的下一个缓存项。扫描持续进行，直到找到一个未被访问的缓存项，该项即为待淘汰的目标。
	1. SIEVE算法通过保留被访问项在队列中的原有位置，减少了重新排序的开销，避免了频繁访问项的过度淘汰。
	2. 通过在队列内部淘汰缓存项并将新项插入队列左侧的方式，SIEVE确保了新项和保留项之间相互隔离。

缓存系统的核心操作包括*访问、插入和淘汰*，这三项操作构成了缓存管理的基础，并直接影响缓存淘汰策略的整体性能。

在基于LRU（最近最少使用）的淘汰策略中，缓存项在被访问时需要被移动到队列头部。为了高效地从任意位置移动缓存项，LRU策略通常实现为双向链表。
与LRU算法不同，SIEVE在访问缓存项时仅更改其引用位而不改变其位置。
然而，SIEVE并未完全摆脱锁的限制。在缓存淘汰过程中，SIEVE仍然需要对缓存队列加锁。SIEVE使用一个指针在队列内循环选择淘汰对象。与LRU策略相似，淘汰队列内部对象时，同时*更改前后节点的指针*，需要互斥锁以确保数据一致性。
相比之下，FIFO和CLOCK淘汰策略更加简洁。它们基于先进先出队列，不需要在内部移动数据，仅涉及入队和出队两种操作。

**结论**：
由于SIEVE在数据访问过程中不使用锁，相较于基于LRU的策略，其吞吐率显著提高。然而，由于SIEVE在数据淘汰时仍需使用锁，其吞吐率低于使用无锁数据结构的FIFO和CLOCK策略。后两者通过无锁数据结构实现了更高的并行性。

### 基于FIFO队列的无锁设计   Mobius
Mobius 采用了一种新方式来规避这一问题：
将 SIEVE 中的单一队列拆分为两个无锁的 FIFO 队列。一个队列专门存储新插入的数据，称为活跃队列（Active Queue）；另一个队列用于存放保留的缓存项，称为休眠队列（Dormant Queue）。
Mobius从活跃队列左侧插入新数据；当缓存达到最大容量时，Mobius 会从活跃队列的右侧移除缓存项。如果该项最近被访问过，Mobius 会将其转移到休眠队列。当活跃队列为空或接近为空时，两个队列的角色会互换。

在基于单向链表的FIFO队列中，入队操作作用于链表尾指针（tail），出队操作作用于链表头指针（head）。入队和出队操作在同一队列上作用于不同的数据项，互不干扰。然而，存在两种边界情况可能会威胁到Mobius的线程安全性。

#### 第一种边界情况发生在*活跃队列为空*时。
假设一次入队操作和一次出队操作作用于同一个空队列。由于队列为空，入队操作需要同时修改头指针和尾指针：更新头指针指向入队数据，更新尾指针指向入队数据。

假设有两个线程T1和T2，T1执行入队操作，T2执行出队操作，则可能出现下述情况：T1更新了头指针， T2将头指针置空，T2将尾指针置空， T1更新了尾指针。此时，尾指针指向了数据，却没有对应的头指针，形成链表状态不一致的问题。

为解决这一问题，Mobius在执行入队操作时，先更新尾指针，再更新头指针。仅当检测到头指针不为空时，执行出队操作，以确保队列状态的一致性。

#### 第二种边界情况发生在*活跃队列即将为空*时。
假设 T1正在执行出队操作，准备移除队列中的最后一个元素，同时 T2正在发起入队操作。T1和T2同时修改头指针和尾指针，可能导致三种最终状态：队列为空、队列包含一个元素，或者队列状态不一致。

Mobius采取了一种简单的预防措施：**确保在活跃队列中剩下最后一个缓存项时就进行队列角色切换**。

### 基于连续检测的缓存淘汰机制
在 Mobius算法中，数据竞争主要由入队和出队操作引起。这两个操作会对临界资源（队列的头指针和尾指针）进行并发修改，引发争用，进而影响并行吞吐率。

缓存淘汰过程中，Mobius会扫描队列中的一段缓存项，并检测其访问状态。如果发现多个连续已被访问的项，Mobius会忽视这些项，直到找到候选淘汰项后，将这些缓存项组成的链表从原链表分离，完成淘汰。此方法有效地降低了缓存淘汰操作的频率，提升了系统效率。

### 无锁缓存管理方案实现
#### 基于FIFO队列的无锁实现
1. 缓存访问：
	1. 与 CLOCK 算法类似，Mobius 在每个缓存项中维护一个访问标记。每当缓存项被用户访问时，该标记会被更新为真。
2. 缓存插入：
	1. Mobius 使用了三项数据结构：两个 FIFO 队列和一个布尔变量，用于指示当前活跃的队列。由于 Mobius 只使用两个队列，这一指示器可以简单地实现为布尔变量。
3. 缓存淘汰：（分析并发竞争）
	1. 分析入队操作：多线程入队操作涉及的临界资源是*尾指针*（tail），其原子性通过 CAS 指令得到保证。
	2. 对同一个空的活动队列进行Enqueue 和淘汰（Evict）操作时：如 [第一种边界情况发生在*活跃队列为空*时。](#第一种边界情况发生在*活跃队列为空*时。) 所示。
	3. 多个并发的 Evict 操作：Evict 操作涉及两个临界变量：whichQ 和活动队列的头指针（head）。Mobius 使用 CAS 原语来确保并行环境中的一致性，即使多个线程同时运行代码，也只有一个线程能够成功更新 whichQ。
#### 连续检测机制
如 Mobius缓存替换算法一文中 [getEvictionCandidate1()：优化淘汰算法](CacheLib-Replacement-Algorithm/Mobius缓存替换算法.md#getEvictionCandidate1()：优化淘汰算法) 一节所示。